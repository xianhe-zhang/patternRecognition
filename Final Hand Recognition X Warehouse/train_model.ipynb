{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1nqwGeQ766U",
        "outputId": "b3c62a87-9ee6-4126-f843-cedde6ed588f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n",
            "Collecting mediapipe-model-maker\n",
            "  Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.4.0)\n",
            "Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n",
            "  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.8.0.76)\n",
            "Requirement already satisfied: tensorflow>=2.10 in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (2.14.0)\n",
            "Collecting tensorflow-addons (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.15.0)\n",
            "Collecting tf-models-official>=2.13.1 (from mediapipe-model-maker)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.7.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.14.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (3.0.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading immutabledict-4.0.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (4.8.1.78)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (6.0.1)\n",
            "Collecting sacrebleu (from tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.11.4)\n",
            "Collecting sentencepiece (from tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Collecting tensorflow-text~=2.15.0 (from tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow>=2.10 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.13.1->mediapipe-model-maker) (1.1.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow>=2.10->mediapipe-model-maker)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.8)\n",
            "Requirement already satisfied: etils>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (1.5.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.66.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.10->mediapipe-model-maker) (0.42.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (3.17.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (6.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.13.1->mediapipe-model-maker) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official>=2.13.1->mediapipe-model-maker) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (1.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.61.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.13.1->mediapipe-model-maker) (5.3.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.13.1->mediapipe-model-maker) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (2.1.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.13.1->mediapipe-model-maker) (1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.10->mediapipe-model-maker) (3.2.2)\n",
            "Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading immutabledict-4.0.0-py3-none-any.whl (4.5 kB)\n",
            "Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=e9178632892b5b0159991a33e9cbe4a3889b4c9c8a0429da85a69c53f5e7b8b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, typeguard, tensorflow-model-optimization, tensorflow-estimator, portalocker, keras, immutabledict, colorama, tensorflow-addons, sounddevice, sacrebleu, seqeval, mediapipe, tensorboard, tensorflow, tensorflow-text, tf-models-official, mediapipe-model-maker\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed colorama-0.4.6 immutabledict-4.0.0 keras-2.15.0 mediapipe-0.10.9 mediapipe-model-maker-0.2.1.3 portalocker-2.8.2 sacrebleu-2.4.0 sentencepiece-0.1.99 seqeval-1.2.2 sounddevice-0.4.6 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-addons-0.23.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-models-official-2.15.0 typeguard-2.13.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOpeVWFQ7_Xa",
        "outputId": "1cc3a596-1452-4466-d4a2-91ff3d0814f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from mediapipe_model_maker import gesture_recognizer\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY7QN2tc8jdb",
        "outputId": "ea3ef165-eee0-4f2e-b38f-754c5d229080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-14 10:50:11--  https://storage.googleapis.com/mediapipe-tasks/gesture_recognizer/rps_data_sample.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.207, 173.194.217.207, 173.194.218.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12332447 (12M) [application/zip]\n",
            "Saving to: ‘rps_data_sample.zip’\n",
            "\n",
            "rps_data_sample.zip 100%[===================>]  11.76M  51.6MB/s    in 0.2s    \n",
            "\n",
            "2023-12-14 10:50:12 (51.6 MB/s) - ‘rps_data_sample.zip’ saved [12332447/12332447]\n",
            "\n",
            "Archive:  rps_data_sample.zip\n",
            "   creating: rps_data_sample/\n",
            "   creating: rps_data_sample/paper/\n",
            "   creating: rps_data_sample/rock/\n",
            "   creating: rps_data_sample/scissors/\n",
            "   creating: rps_data_sample/none/\n",
            "  inflating: rps_data_sample/paper/77.jpg  \n",
            "  inflating: rps_data_sample/paper/837.jpg  \n",
            "  inflating: rps_data_sample/paper/176.jpg  \n",
            "  inflating: rps_data_sample/paper/406.jpg  \n",
            "  inflating: rps_data_sample/paper/771.jpg  \n",
            "  inflating: rps_data_sample/paper/89.jpg  \n",
            "  inflating: rps_data_sample/paper/76.jpg  \n",
            "  inflating: rps_data_sample/paper/74.jpg  \n",
            "  inflating: rps_data_sample/paper/439.jpg  \n",
            "  inflating: rps_data_sample/paper/411.jpg  \n",
            "  inflating: rps_data_sample/paper/955.jpg  \n",
            "  inflating: rps_data_sample/paper/941.jpg  \n",
            "  inflating: rps_data_sample/paper/170.jpg  \n",
            "  inflating: rps_data_sample/paper/158.jpg  \n",
            "  inflating: rps_data_sample/paper/206.jpg  \n",
            "  inflating: rps_data_sample/paper/944.jpg  \n",
            "  inflating: rps_data_sample/paper/575.jpg  \n",
            "  inflating: rps_data_sample/paper/401.jpg  \n",
            "  inflating: rps_data_sample/paper/165.jpg  \n",
            "  inflating: rps_data_sample/paper/818.jpg  \n",
            "  inflating: rps_data_sample/paper/72.jpg  \n",
            "  inflating: rps_data_sample/paper/832.jpg  \n",
            "  inflating: rps_data_sample/paper/601.jpg  \n",
            "  inflating: rps_data_sample/paper/628.jpg  \n",
            "  inflating: rps_data_sample/paper/166.jpg  \n",
            "  inflating: rps_data_sample/paper/465.jpg  \n",
            "  inflating: rps_data_sample/paper/539.jpg  \n",
            "  inflating: rps_data_sample/paper/505.jpg  \n",
            "  inflating: rps_data_sample/paper/935.jpg  \n",
            "  inflating: rps_data_sample/paper/504.jpg  \n",
            "  inflating: rps_data_sample/paper/276.jpg  \n",
            "  inflating: rps_data_sample/paper/302.jpg  \n",
            "  inflating: rps_data_sample/paper/666.jpg  \n",
            "  inflating: rps_data_sample/paper/855.jpg  \n",
            "  inflating: rps_data_sample/paper/658.jpg  \n",
            "  inflating: rps_data_sample/paper/472.jpg  \n",
            "  inflating: rps_data_sample/paper/249.jpg  \n",
            "  inflating: rps_data_sample/paper/103.jpg  \n",
            "  inflating: rps_data_sample/paper/846.jpg  \n",
            "  inflating: rps_data_sample/paper/891.jpg  \n",
            "  inflating: rps_data_sample/paper/477.jpg  \n",
            "  inflating: rps_data_sample/paper/339.jpg  \n",
            "  inflating: rps_data_sample/paper/701.jpg  \n",
            "  inflating: rps_data_sample/paper/258.jpg  \n",
            "  inflating: rps_data_sample/paper/884.jpg  \n",
            "  inflating: rps_data_sample/paper/890.jpg  \n",
            "  inflating: rps_data_sample/paper/847.jpg  \n",
            "  inflating: rps_data_sample/paper/879.jpg  \n",
            "  inflating: rps_data_sample/paper/306.jpg  \n",
            "  inflating: rps_data_sample/paper/460.jpg  \n",
            "  inflating: rps_data_sample/paper/299.jpg  \n",
            "  inflating: rps_data_sample/paper/919.jpg  \n",
            "  inflating: rps_data_sample/paper/717.jpg  \n",
            "  inflating: rps_data_sample/paper/918.jpg  \n",
            "  inflating: rps_data_sample/paper/529.jpg  \n",
            "  inflating: rps_data_sample/paper/461.jpg  \n",
            "  inflating: rps_data_sample/paper/887.jpg  \n",
            "  inflating: rps_data_sample/paper/677.jpg  \n",
            "  inflating: rps_data_sample/paper/844.jpg  \n",
            "  inflating: rps_data_sample/paper/518.jpg  \n",
            "  inflating: rps_data_sample/paper/901.jpg  \n",
            "  inflating: rps_data_sample/paper/531.jpg  \n",
            "  inflating: rps_data_sample/paper/690.jpg  \n",
            "  inflating: rps_data_sample/paper/321.jpg  \n",
            "  inflating: rps_data_sample/paper/282.jpg  \n",
            "  inflating: rps_data_sample/paper/269.jpg  \n",
            "  inflating: rps_data_sample/paper/533.jpg  \n",
            "  inflating: rps_data_sample/paper/719.jpg  \n",
            "  inflating: rps_data_sample/paper/730.jpg  \n",
            "  inflating: rps_data_sample/paper/283.jpg  \n",
            "  inflating: rps_data_sample/paper/37.jpg  \n",
            "  inflating: rps_data_sample/paper/654.jpg  \n",
            "  inflating: rps_data_sample/paper/898.jpg  \n",
            "  inflating: rps_data_sample/paper/495.jpg  \n",
            "  inflating: rps_data_sample/paper/318.jpg  \n",
            "  inflating: rps_data_sample/paper/278.jpg  \n",
            "  inflating: rps_data_sample/paper/734.jpg  \n",
            "  inflating: rps_data_sample/paper/537.jpg  \n",
            "  inflating: rps_data_sample/paper/319.jpg  \n",
            "  inflating: rps_data_sample/paper/655.jpg  \n",
            "  inflating: rps_data_sample/paper/680.jpg  \n",
            "  inflating: rps_data_sample/paper/18.jpg  \n",
            "  inflating: rps_data_sample/paper/24.jpg  \n",
            "  inflating: rps_data_sample/paper/657.jpg  \n",
            "  inflating: rps_data_sample/paper/119.jpg  \n",
            "  inflating: rps_data_sample/paper/482.jpg  \n",
            "  inflating: rps_data_sample/paper/284.jpg  \n",
            "  inflating: rps_data_sample/paper/905.jpg  \n",
            "  inflating: rps_data_sample/paper/483.jpg  \n",
            "  inflating: rps_data_sample/paper/865.jpg  \n",
            "  inflating: rps_data_sample/paper/25.jpg  \n",
            "  inflating: rps_data_sample/paper/194.jpg  \n",
            "  inflating: rps_data_sample/paper/143.jpg  \n",
            "  inflating: rps_data_sample/paper/744.jpg  \n",
            "  inflating: rps_data_sample/paper/977.jpg  \n",
            "  inflating: rps_data_sample/paper/142.jpg  \n",
            "  inflating: rps_data_sample/paper/80.jpg  \n",
            "  inflating: rps_data_sample/paper/57.jpg  \n",
            "  inflating: rps_data_sample/paper/7.jpg  \n",
            "  inflating: rps_data_sample/paper/183.jpg  \n",
            "  inflating: rps_data_sample/paper/395.jpg  \n",
            "  inflating: rps_data_sample/paper/544.jpg  \n",
            "  inflating: rps_data_sample/paper/236.jpg  \n",
            "  inflating: rps_data_sample/paper/785.jpg  \n",
            "  inflating: rps_data_sample/paper/791.jpg  \n",
            "  inflating: rps_data_sample/paper/394.jpg  \n",
            "  inflating: rps_data_sample/paper/54.jpg  \n",
            "  inflating: rps_data_sample/paper/192.jpg  \n",
            "  inflating: rps_data_sample/paper/838.jpg  \n",
            "  inflating: rps_data_sample/paper/50.jpg  \n",
            "  inflating: rps_data_sample/paper/179.jpg  \n",
            "  inflating: rps_data_sample/paper/227.jpg  \n",
            "  inflating: rps_data_sample/paper/757.jpg  \n",
            "  inflating: rps_data_sample/paper/971.jpg  \n",
            "  inflating: rps_data_sample/paper/811.jpg  \n",
            "  inflating: rps_data_sample/paper/51.jpg  \n",
            "  inflating: rps_data_sample/paper/53.jpg  \n",
            "  inflating: rps_data_sample/paper/146.jpg  \n",
            "  inflating: rps_data_sample/paper/620.jpg  \n",
            "  inflating: rps_data_sample/paper/393.jpg  \n",
            "  inflating: rps_data_sample/paper/973.jpg  \n",
            "  inflating: rps_data_sample/paper/594.jpg  \n",
            "  inflating: rps_data_sample/paper/423.jpg  \n",
            "  inflating: rps_data_sample/paper/91.jpg  \n",
            "  inflating: rps_data_sample/paper/806.jpg  \n",
            "  inflating: rps_data_sample/rock/88.jpg  \n",
            "  inflating: rps_data_sample/rock/348.jpg  \n",
            "  inflating: rps_data_sample/rock/360.jpg  \n",
            "  inflating: rps_data_sample/rock/764.jpg  \n",
            "  inflating: rps_data_sample/rock/771.jpg  \n",
            "  inflating: rps_data_sample/rock/942.jpg  \n",
            "  inflating: rps_data_sample/rock/956.jpg  \n",
            "  inflating: rps_data_sample/rock/567.jpg  \n",
            "  inflating: rps_data_sample/rock/407.jpg  \n",
            "  inflating: rps_data_sample/rock/834.jpg  \n",
            "  inflating: rps_data_sample/rock/363.jpg  \n",
            "  inflating: rps_data_sample/rock/565.jpg  \n",
            "  inflating: rps_data_sample/rock/772.jpg  \n",
            "  inflating: rps_data_sample/rock/216.jpg  \n",
            "  inflating: rps_data_sample/rock/376.jpg  \n",
            "  inflating: rps_data_sample/rock/399.jpg  \n",
            "  inflating: rps_data_sample/rock/372.jpg  \n",
            "  inflating: rps_data_sample/rock/428.jpg  \n",
            "  inflating: rps_data_sample/rock/560.jpg  \n",
            "  inflating: rps_data_sample/rock/206.jpg  \n",
            "  inflating: rps_data_sample/rock/548.jpg  \n",
            "  inflating: rps_data_sample/rock/945.jpg  \n",
            "  inflating: rps_data_sample/rock/776.jpg  \n",
            "  inflating: rps_data_sample/rock/549.jpg  \n",
            "  inflating: rps_data_sample/rock/398.jpg  \n",
            "  inflating: rps_data_sample/rock/165.jpg  \n",
            "  inflating: rps_data_sample/rock/617.jpg  \n",
            "  inflating: rps_data_sample/rock/818.jpg  \n",
            "  inflating: rps_data_sample/rock/211.jpg  \n",
            "  inflating: rps_data_sample/rock/239.jpg  \n",
            "  inflating: rps_data_sample/rock/760.jpg  \n",
            "  inflating: rps_data_sample/rock/238.jpg  \n",
            "  inflating: rps_data_sample/rock/416.jpg  \n",
            "  inflating: rps_data_sample/rock/614.jpg  \n",
            "  inflating: rps_data_sample/rock/854.jpg  \n",
            "  inflating: rps_data_sample/rock/28.jpg  \n",
            "  inflating: rps_data_sample/rock/868.jpg  \n",
            "  inflating: rps_data_sample/rock/302.jpg  \n",
            "  inflating: rps_data_sample/rock/672.jpg  \n",
            "  inflating: rps_data_sample/rock/896.jpg  \n",
            "  inflating: rps_data_sample/rock/894.jpg  \n",
            "  inflating: rps_data_sample/rock/328.jpg  \n",
            "  inflating: rps_data_sample/rock/300.jpg  \n",
            "  inflating: rps_data_sample/rock/922.jpg  \n",
            "  inflating: rps_data_sample/rock/513.jpg  \n",
            "  inflating: rps_data_sample/rock/507.jpg  \n",
            "  inflating: rps_data_sample/rock/329.jpg  \n",
            "  inflating: rps_data_sample/rock/675.jpg  \n",
            "  inflating: rps_data_sample/rock/891.jpg  \n",
            "  inflating: rps_data_sample/rock/305.jpg  \n",
            "  inflating: rps_data_sample/rock/728.jpg  \n",
            "  inflating: rps_data_sample/rock/648.jpg  \n",
            "  inflating: rps_data_sample/rock/851.jpg  \n",
            "  inflating: rps_data_sample/rock/931.jpg  \n",
            "  inflating: rps_data_sample/rock/529.jpg  \n",
            "  inflating: rps_data_sample/rock/449.jpg  \n",
            "  inflating: rps_data_sample/rock/850.jpg  \n",
            "  inflating: rps_data_sample/rock/861.jpg  \n",
            "  inflating: rps_data_sample/rock/875.jpg  \n",
            "  inflating: rps_data_sample/rock/524.jpg  \n",
            "  inflating: rps_data_sample/rock/915.jpg  \n",
            "  inflating: rps_data_sample/rock/901.jpg  \n",
            "  inflating: rps_data_sample/rock/929.jpg  \n",
            "  inflating: rps_data_sample/rock/733.jpg  \n",
            "  inflating: rps_data_sample/rock/309.jpg  \n",
            "  inflating: rps_data_sample/rock/254.jpg  \n",
            "  inflating: rps_data_sample/rock/320.jpg  \n",
            "  inflating: rps_data_sample/rock/687.jpg  \n",
            "  inflating: rps_data_sample/rock/318.jpg  \n",
            "  inflating: rps_data_sample/rock/244.jpg  \n",
            "  inflating: rps_data_sample/rock/536.jpg  \n",
            "  inflating: rps_data_sample/rock/709.jpg  \n",
            "  inflating: rps_data_sample/rock/906.jpg  \n",
            "  inflating: rps_data_sample/rock/537.jpg  \n",
            "  inflating: rps_data_sample/rock/523.jpg  \n",
            "  inflating: rps_data_sample/rock/286.jpg  \n",
            "  inflating: rps_data_sample/rock/133.jpg  \n",
            "  inflating: rps_data_sample/rock/872.jpg  \n",
            "  inflating: rps_data_sample/rock/32.jpg  \n",
            "  inflating: rps_data_sample/rock/30.jpg  \n",
            "  inflating: rps_data_sample/rock/441.jpg  \n",
            "  inflating: rps_data_sample/rock/290.jpg  \n",
            "  inflating: rps_data_sample/rock/938.jpg  \n",
            "  inflating: rps_data_sample/rock/904.jpg  \n",
            "  inflating: rps_data_sample/rock/722.jpg  \n",
            "  inflating: rps_data_sample/rock/905.jpg  \n",
            "  inflating: rps_data_sample/rock/285.jpg  \n",
            "  inflating: rps_data_sample/rock/56.jpg  \n",
            "  inflating: rps_data_sample/rock/625.jpg  \n",
            "  inflating: rps_data_sample/rock/427.jpg  \n",
            "  inflating: rps_data_sample/rock/750.jpg  \n",
            "  inflating: rps_data_sample/rock/778.jpg  \n",
            "  inflating: rps_data_sample/rock/546.jpg  \n",
            "  inflating: rps_data_sample/rock/234.jpg  \n",
            "  inflating: rps_data_sample/rock/426.jpg  \n",
            "  inflating: rps_data_sample/rock/168.jpg  \n",
            "  inflating: rps_data_sample/rock/82.jpg  \n",
            "  inflating: rps_data_sample/rock/356.jpg  \n",
            "  inflating: rps_data_sample/rock/593.jpg  \n",
            "  inflating: rps_data_sample/rock/784.jpg  \n",
            "  inflating: rps_data_sample/rock/223.jpg  \n",
            "  inflating: rps_data_sample/rock/545.jpg  \n",
            "  inflating: rps_data_sample/rock/592.jpg  \n",
            "  inflating: rps_data_sample/rock/431.jpg  \n",
            "  inflating: rps_data_sample/rock/182.jpg  \n",
            "  inflating: rps_data_sample/rock/54.jpg  \n",
            "  inflating: rps_data_sample/rock/186.jpg  \n",
            "  inflating: rps_data_sample/rock/435.jpg  \n",
            "  inflating: rps_data_sample/rock/409.jpg  \n",
            "  inflating: rps_data_sample/rock/541.jpg  \n",
            "  inflating: rps_data_sample/rock/45.jpg  \n",
            "  inflating: rps_data_sample/rock/193.jpg  \n",
            "  inflating: rps_data_sample/rock/47.jpg  \n",
            "  inflating: rps_data_sample/rock/1.jpg  \n",
            "  inflating: rps_data_sample/rock/152.jpg  \n",
            "  inflating: rps_data_sample/rock/595.jpg  \n",
            "  inflating: rps_data_sample/rock/218.jpg  \n",
            "  inflating: rps_data_sample/rock/967.jpg  \n",
            "  inflating: rps_data_sample/rock/769.jpg  \n",
            "  inflating: rps_data_sample/rock/796.jpg  \n",
            "  inflating: rps_data_sample/rock/351.jpg  \n",
            "  inflating: rps_data_sample/rock/392.jpg  \n",
            "  inflating: rps_data_sample/rock/635.jpg  \n",
            "  inflating: rps_data_sample/rock/147.jpg  \n",
            "  inflating: rps_data_sample/rock/621.jpg  \n",
            "  inflating: rps_data_sample/scissors/604.jpg  \n",
            "  inflating: rps_data_sample/scissors/162.jpg  \n",
            "  inflating: rps_data_sample/scissors/610.jpg  \n",
            "  inflating: rps_data_sample/scissors/764.jpg  \n",
            "  inflating: rps_data_sample/scissors/942.jpg  \n",
            "  inflating: rps_data_sample/scissors/188.jpg  \n",
            "  inflating: rps_data_sample/scissors/60.jpg  \n",
            "  inflating: rps_data_sample/scissors/149.jpg  \n",
            "  inflating: rps_data_sample/scissors/559.jpg  \n",
            "  inflating: rps_data_sample/scissors/798.jpg  \n",
            "  inflating: rps_data_sample/scissors/954.jpg  \n",
            "  inflating: rps_data_sample/scissors/968.jpg  \n",
            "  inflating: rps_data_sample/scissors/49.jpg  \n",
            "  inflating: rps_data_sample/scissors/819.jpg  \n",
            "  inflating: rps_data_sample/scissors/602.jpg  \n",
            "  inflating: rps_data_sample/scissors/400.jpg  \n",
            "  inflating: rps_data_sample/scissors/428.jpg  \n",
            "  inflating: rps_data_sample/scissors/788.jpg  \n",
            "  inflating: rps_data_sample/scissors/549.jpg  \n",
            "  inflating: rps_data_sample/scissors/617.jpg  \n",
            "  inflating: rps_data_sample/scissors/64.jpg  \n",
            "  inflating: rps_data_sample/scissors/70.jpg  \n",
            "  inflating: rps_data_sample/scissors/173.jpg  \n",
            "  inflating: rps_data_sample/scissors/239.jpg  \n",
            "  inflating: rps_data_sample/scissors/760.jpg  \n",
            "  inflating: rps_data_sample/scissors/589.jpg  \n",
            "  inflating: rps_data_sample/scissors/614.jpg  \n",
            "  inflating: rps_data_sample/scissors/14.jpg  \n",
            "  inflating: rps_data_sample/scissors/28.jpg  \n",
            "  inflating: rps_data_sample/scissors/129.jpg  \n",
            "  inflating: rps_data_sample/scissors/673.jpg  \n",
            "  inflating: rps_data_sample/scissors/707.jpg  \n",
            "  inflating: rps_data_sample/scissors/706.jpg  \n",
            "  inflating: rps_data_sample/scissors/276.jpg  \n",
            "  inflating: rps_data_sample/scissors/289.jpg  \n",
            "  inflating: rps_data_sample/scissors/100.jpg  \n",
            "  inflating: rps_data_sample/scissors/29.jpg  \n",
            "  inflating: rps_data_sample/scissors/116.jpg  \n",
            "  inflating: rps_data_sample/scissors/670.jpg  \n",
            "  inflating: rps_data_sample/scissors/705.jpg  \n",
            "  inflating: rps_data_sample/scissors/261.jpg  \n",
            "  inflating: rps_data_sample/scissors/301.jpg  \n",
            "  inflating: rps_data_sample/scissors/117.jpg  \n",
            "  inflating: rps_data_sample/scissors/856.jpg  \n",
            "  inflating: rps_data_sample/scissors/16.jpg  \n",
            "  inflating: rps_data_sample/scissors/463.jpg  \n",
            "  inflating: rps_data_sample/scissors/715.jpg  \n",
            "  inflating: rps_data_sample/scissors/927.jpg  \n",
            "  inflating: rps_data_sample/scissors/264.jpg  \n",
            "  inflating: rps_data_sample/scissors/338.jpg  \n",
            "  inflating: rps_data_sample/scissors/476.jpg  \n",
            "  inflating: rps_data_sample/scissors/853.jpg  \n",
            "  inflating: rps_data_sample/scissors/104.jpg  \n",
            "  inflating: rps_data_sample/scissors/306.jpg  \n",
            "  inflating: rps_data_sample/scissors/448.jpg  \n",
            "  inflating: rps_data_sample/scissors/925.jpg  \n",
            "  inflating: rps_data_sample/scissors/930.jpg  \n",
            "  inflating: rps_data_sample/scissors/878.jpg  \n",
            "  inflating: rps_data_sample/scissors/691.jpg  \n",
            "  inflating: rps_data_sample/scissors/732.jpg  \n",
            "  inflating: rps_data_sample/scissors/531.jpg  \n",
            "  inflating: rps_data_sample/scissors/323.jpg  \n",
            "  inflating: rps_data_sample/scissors/684.jpg  \n",
            "  inflating: rps_data_sample/scissors/321.jpg  \n",
            "  inflating: rps_data_sample/scissors/269.jpg  \n",
            "  inflating: rps_data_sample/scissors/527.jpg  \n",
            "  inflating: rps_data_sample/scissors/730.jpg  \n",
            "  inflating: rps_data_sample/scissors/122.jpg  \n",
            "  inflating: rps_data_sample/scissors/23.jpg  \n",
            "  inflating: rps_data_sample/scissors/126.jpg  \n",
            "  inflating: rps_data_sample/scissors/293.jpg  \n",
            "  inflating: rps_data_sample/scissors/522.jpg  \n",
            "  inflating: rps_data_sample/scissors/278.jpg  \n",
            "  inflating: rps_data_sample/scissors/720.jpg  \n",
            "  inflating: rps_data_sample/scissors/251.jpg  \n",
            "  inflating: rps_data_sample/scissors/641.jpg  \n",
            "  inflating: rps_data_sample/scissors/866.jpg  \n",
            "  inflating: rps_data_sample/scissors/657.jpg  \n",
            "  inflating: rps_data_sample/scissors/119.jpg  \n",
            "  inflating: rps_data_sample/scissors/482.jpg  \n",
            "  inflating: rps_data_sample/scissors/520.jpg  \n",
            "  inflating: rps_data_sample/scissors/534.jpg  \n",
            "  inflating: rps_data_sample/scissors/285.jpg  \n",
            "  inflating: rps_data_sample/scissors/656.jpg  \n",
            "  inflating: rps_data_sample/scissors/871.jpg  \n",
            "  inflating: rps_data_sample/scissors/56.jpg  \n",
            "  inflating: rps_data_sample/scissors/631.jpg  \n",
            "  inflating: rps_data_sample/scissors/382.jpg  \n",
            "  inflating: rps_data_sample/scissors/792.jpg  \n",
            "  inflating: rps_data_sample/scissors/208.jpg  \n",
            "  inflating: rps_data_sample/scissors/397.jpg  \n",
            "  inflating: rps_data_sample/scissors/156.jpg  \n",
            "  inflating: rps_data_sample/scissors/630.jpg  \n",
            "  inflating: rps_data_sample/scissors/5.jpg  \n",
            "  inflating: rps_data_sample/scissors/57.jpg  \n",
            "  inflating: rps_data_sample/scissors/803.jpg  \n",
            "  inflating: rps_data_sample/scissors/7.jpg  \n",
            "  inflating: rps_data_sample/scissors/96.jpg  \n",
            "  inflating: rps_data_sample/scissors/222.jpg  \n",
            "  inflating: rps_data_sample/scissors/550.jpg  \n",
            "  inflating: rps_data_sample/scissors/785.jpg  \n",
            "  inflating: rps_data_sample/scissors/791.jpg  \n",
            "  inflating: rps_data_sample/scissors/753.jpg  \n",
            "  inflating: rps_data_sample/scissors/223.jpg  \n",
            "  inflating: rps_data_sample/scissors/394.jpg  \n",
            "  inflating: rps_data_sample/scissors/169.jpg  \n",
            "  inflating: rps_data_sample/scissors/196.jpg  \n",
            "  inflating: rps_data_sample/scissors/800.jpg  \n",
            "  inflating: rps_data_sample/scissors/192.jpg  \n",
            "  inflating: rps_data_sample/scissors/50.jpg  \n",
            "  inflating: rps_data_sample/scissors/804.jpg  \n",
            "  inflating: rps_data_sample/scissors/596.jpg  \n",
            "  inflating: rps_data_sample/scissors/568.jpg  \n",
            "  inflating: rps_data_sample/scissors/232.jpg  \n",
            "  inflating: rps_data_sample/scissors/45.jpg  \n",
            "  inflating: rps_data_sample/scissors/90.jpg  \n",
            "  inflating: rps_data_sample/scissors/387.jpg  \n",
            "  inflating: rps_data_sample/scissors/436.jpg  \n",
            "  inflating: rps_data_sample/scissors/378.jpg  \n",
            "  inflating: rps_data_sample/scissors/595.jpg  \n",
            "  inflating: rps_data_sample/scissors/230.jpg  \n",
            "  inflating: rps_data_sample/scissors/782.jpg  \n",
            "  inflating: rps_data_sample/scissors/580.jpg  \n",
            "  inflating: rps_data_sample/scissors/147.jpg  \n",
            "  inflating: rps_data_sample/scissors/184.jpg  \n",
            "  inflating: rps_data_sample/none/823.jpg  \n",
            "  inflating: rps_data_sample/none/1031.jpg  \n",
            "  inflating: rps_data_sample/none/957.jpg  \n",
            "  inflating: rps_data_sample/none/229.jpg  \n",
            "  inflating: rps_data_sample/none/598.jpg  \n",
            "  inflating: rps_data_sample/none/349.jpg  \n",
            "  inflating: rps_data_sample/none/1811.jpg  \n",
            "  inflating: rps_data_sample/none/76.jpg  \n",
            "  inflating: rps_data_sample/none/60.jpg  \n",
            "  inflating: rps_data_sample/none/820.jpg  \n",
            "  inflating: rps_data_sample/none/613.jpg  \n",
            "  inflating: rps_data_sample/none/363.jpg  \n",
            "  inflating: rps_data_sample/none/203.jpg  \n",
            "  inflating: rps_data_sample/none/1224.jpg  \n",
            "  inflating: rps_data_sample/none/955.jpg  \n",
            "  inflating: rps_data_sample/none/941.jpg  \n",
            "  inflating: rps_data_sample/none/1033.jpg  \n",
            "  inflating: rps_data_sample/none/1812.jpg  \n",
            "  inflating: rps_data_sample/none/1609.jpg  \n",
            "  inflating: rps_data_sample/none/71.jpg  \n",
            "  inflating: rps_data_sample/none/65.jpg  \n",
            "  inflating: rps_data_sample/none/1802.jpg  \n",
            "  inflating: rps_data_sample/none/1590.jpg  \n",
            "  inflating: rps_data_sample/none/993.jpg  \n",
            "  inflating: rps_data_sample/none/950.jpg  \n",
            "  inflating: rps_data_sample/none/1552.jpg  \n",
            "  inflating: rps_data_sample/none/213.jpg  \n",
            "  inflating: rps_data_sample/none/165.jpg  \n",
            "  inflating: rps_data_sample/none/1340.jpg  \n",
            "  inflating: rps_data_sample/none/1424.jpg  \n",
            "  inflating: rps_data_sample/none/1381.jpg  \n",
            "  inflating: rps_data_sample/none/239.jpg  \n",
            "  inflating: rps_data_sample/none/946.jpg  \n",
            "  inflating: rps_data_sample/none/1784.jpg  \n",
            "  inflating: rps_data_sample/none/1747.jpg  \n",
            "  inflating: rps_data_sample/none/1814.jpg  \n",
            "  inflating: rps_data_sample/none/1627.jpg  \n",
            "  inflating: rps_data_sample/none/1633.jpg  \n",
            "  inflating: rps_data_sample/none/9.jpg  \n",
            "  inflating: rps_data_sample/none/511.jpg  \n",
            "  inflating: rps_data_sample/none/1244.jpg  \n",
            "  inflating: rps_data_sample/none/1906.jpg  \n",
            "  inflating: rps_data_sample/none/1469.jpg  \n",
            "  inflating: rps_data_sample/none/1119.jpg  \n",
            "  inflating: rps_data_sample/none/1643.jpg  \n",
            "  inflating: rps_data_sample/none/1657.jpg  \n",
            "  inflating: rps_data_sample/none/1521.jpg  \n",
            "  inflating: rps_data_sample/none/704.jpg  \n",
            "  inflating: rps_data_sample/none/1534.jpg  \n",
            "  inflating: rps_data_sample/none/275.jpg  \n",
            "  inflating: rps_data_sample/none/249.jpg  \n",
            "  inflating: rps_data_sample/none/1134.jpg  \n",
            "  inflating: rps_data_sample/none/1083.jpg  \n",
            "  inflating: rps_data_sample/none/729.jpg  \n",
            "  inflating: rps_data_sample/none/270.jpg  \n",
            "  inflating: rps_data_sample/none/1041.jpg  \n",
            "  inflating: rps_data_sample/none/39.jpg  \n",
            "  inflating: rps_data_sample/none/1876.jpg  \n",
            "  inflating: rps_data_sample/none/1255.jpg  \n",
            "  inflating: rps_data_sample/none/1650.jpg  \n",
            "  inflating: rps_data_sample/none/1308.jpg  \n",
            "  inflating: rps_data_sample/none/1446.jpg  \n",
            "  inflating: rps_data_sample/none/1488.jpg  \n",
            "  inflating: rps_data_sample/none/1885.jpg  \n",
            "  inflating: rps_data_sample/none/1107.jpg  \n",
            "  inflating: rps_data_sample/none/1729.jpg  \n",
            "  inflating: rps_data_sample/none/1067.jpg  \n",
            "  inflating: rps_data_sample/none/1072.jpg  \n",
            "  inflating: rps_data_sample/none/1890.jpg  \n",
            "  inflating: rps_data_sample/none/1851.jpg  \n",
            "  inflating: rps_data_sample/none/255.jpg  \n",
            "  inflating: rps_data_sample/none/1299.jpg  \n",
            "  inflating: rps_data_sample/none/1501.jpg  \n",
            "  inflating: rps_data_sample/none/334.jpg  \n",
            "  inflating: rps_data_sample/none/1878.jpg  \n",
            "  inflating: rps_data_sample/none/1663.jpg  \n",
            "  inflating: rps_data_sample/none/122.jpg  \n",
            "  inflating: rps_data_sample/none/136.jpg  \n",
            "  inflating: rps_data_sample/none/33.jpg  \n",
            "  inflating: rps_data_sample/none/898.jpg  \n",
            "  inflating: rps_data_sample/none/1101.jpg  \n",
            "  inflating: rps_data_sample/none/1883.jpg  \n",
            "  inflating: rps_data_sample/none/735.jpg  \n",
            "  inflating: rps_data_sample/none/1048.jpg  \n",
            "  inflating: rps_data_sample/none/292.jpg  \n",
            "  inflating: rps_data_sample/none/1712.jpg  \n",
            "  inflating: rps_data_sample/none/1128.jpg  \n",
            "  inflating: rps_data_sample/none/32.jpg  \n",
            "  inflating: rps_data_sample/none/657.jpg  \n",
            "  inflating: rps_data_sample/none/327.jpg  \n",
            "  inflating: rps_data_sample/none/1843.jpg  \n",
            "  inflating: rps_data_sample/none/1089.jpg  \n",
            "  inflating: rps_data_sample/none/939.jpg  \n",
            "  inflating: rps_data_sample/none/520.jpg  \n",
            "  inflating: rps_data_sample/none/252.jpg  \n",
            "  inflating: rps_data_sample/none/802.jpg  \n",
            "  inflating: rps_data_sample/none/433.jpg  \n",
            "  inflating: rps_data_sample/none/590.jpg  \n",
            "  inflating: rps_data_sample/none/1206.jpg  \n",
            "  inflating: rps_data_sample/none/779.jpg  \n",
            "  inflating: rps_data_sample/none/744.jpg  \n",
            "  inflating: rps_data_sample/none/1005.jpg  \n",
            "  inflating: rps_data_sample/none/142.jpg  \n",
            "  inflating: rps_data_sample/none/57.jpg  \n",
            "  inflating: rps_data_sample/none/1198.jpg  \n",
            "  inflating: rps_data_sample/none/424.jpg  \n",
            "  inflating: rps_data_sample/none/236.jpg  \n",
            "  inflating: rps_data_sample/none/791.jpg  \n",
            "  inflating: rps_data_sample/none/394.jpg  \n",
            "  inflating: rps_data_sample/none/1416.jpg  \n",
            "  inflating: rps_data_sample/none/800.jpg  \n",
            "  inflating: rps_data_sample/none/1412.jpg  \n",
            "  inflating: rps_data_sample/none/44.jpg  \n",
            "  inflating: rps_data_sample/none/1823.jpg  \n",
            "  inflating: rps_data_sample/none/1189.jpg  \n",
            "  inflating: rps_data_sample/none/1214.jpg  \n",
            "  inflating: rps_data_sample/none/794.jpg  \n",
            "  inflating: rps_data_sample/none/756.jpg  \n",
            "  inflating: rps_data_sample/none/193.jpg  \n",
            "  inflating: rps_data_sample/none/1799.jpg  \n",
            "  inflating: rps_data_sample/none/1000.jpg  \n",
            "  inflating: rps_data_sample/none/386.jpg  \n",
            "  inflating: rps_data_sample/none/1362.jpg  \n",
            "  inflating: rps_data_sample/none/190.jpg  \n",
            "  inflating: rps_data_sample/none/1376.jpg  \n"
          ]
        }
      ],
      "source": [
        "# To get the dataset to train the model\n",
        "!wget https://storage.googleapis.com/mediapipe-tasks/gesture_recognizer/rps_data_sample.zip\n",
        "!unzip rps_data_sample.zip\n",
        "dataset_path = \"rps_data_sample\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPZAk_YL81pH",
        "outputId": "83987bcc-0f06-4882-dc1e-9cae15126743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rps_data_sample\n",
            "['scissors', 'rock', 'none', 'paper']\n"
          ]
        }
      ],
      "source": [
        "# Print out the dataset in our folder and labels.\n",
        "print(dataset_path)\n",
        "labels = []\n",
        "for i in os.listdir(dataset_path):\n",
        "  if os.path.isdir(os.path.join(dataset_path, i)):\n",
        "    labels.append(i)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY0imvtC85e5",
        "outputId": "90eea429-9d5b-4389-8eec-2e666d845713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rps_data_sample/scissors\n",
            "['276.jpg', '954.jpg', '387.jpg', '856.jpg', '730.jpg']\n",
            "rps_data_sample/rock\n",
            "['709.jpg', '548.jpg', '152.jpg', '427.jpg', '945.jpg']\n",
            "rps_data_sample/none\n",
            "['1067.jpg', '349.jpg', '1906.jpg', '939.jpg', '39.jpg']\n",
            "rps_data_sample/paper\n",
            "['276.jpg', '53.jpg', '283.jpg', '744.jpg', '717.jpg']\n"
          ]
        }
      ],
      "source": [
        "# this block is to visualize our data\n",
        "NUM_EXAMPLES = 5\n",
        "\n",
        "for label in labels:\n",
        "  label_dir = os.path.join(dataset_path, label)\n",
        "  print(label_dir)\n",
        "  example_filenames = os.listdir(label_dir)[:NUM_EXAMPLES]\n",
        "  print(example_filenames)\n",
        "#   fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n",
        "#   for i in range(NUM_EXAMPLES):\n",
        "#     axs[i].imshow(plt.imread(os.path.join(label_dir, example_filenames[i])))\n",
        "#     axs[i].get_xaxis().set_visible(False)\n",
        "#     axs[i].get_yaxis().set_visible(False)\n",
        "#   fig.suptitle(f'Showing {NUM_EXAMPLES} examples for {label}')\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf02L8lW8_4d",
        "outputId": "3511d54d-13bd-4962-f541-20bb7531cd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://storage.googleapis.com/mediapipe-assets/palm_detection_full.tflite to /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Downloading https://storage.googleapis.com/mediapipe-assets/hand_landmark_full.tflite to /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tar.gz to /tmp/model_maker/gesture_recognizer/gesture_embedder\n"
          ]
        }
      ],
      "source": [
        "# To split data\n",
        "data = gesture_recognizer.Dataset.from_folder(\n",
        "    dirname=dataset_path,\n",
        "    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
        ")\n",
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulm-Yt9S-C4k",
        "outputId": "116f94dc-79a4-4181-91bf-0ad0dddf86dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hand_embedding (InputLayer  [(None, 128)]             0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 128)               512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 128)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " custom_gesture_recognizer_  (None, 4)                 516       \n",
            " out (Dense)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1028 (4.02 KB)\n",
            "Trainable params: 772 (3.02 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "189/189 [==============================] - 3s 9ms/step - loss: 0.7573 - categorical_accuracy: 0.3889 - val_loss: 0.5858 - val_categorical_accuracy: 0.7021 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.6083 - categorical_accuracy: 0.4974 - val_loss: 0.4720 - val_categorical_accuracy: 0.7660 - lr: 9.9000e-04\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.5346 - categorical_accuracy: 0.5423 - val_loss: 0.4164 - val_categorical_accuracy: 0.8085 - lr: 9.8010e-04\n",
            "Epoch 4/10\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.5136 - categorical_accuracy: 0.5952 - val_loss: 0.3901 - val_categorical_accuracy: 0.8085 - lr: 9.7030e-04\n",
            "Epoch 5/10\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.4837 - categorical_accuracy: 0.6323 - val_loss: 0.3539 - val_categorical_accuracy: 0.8085 - lr: 9.6060e-04\n",
            "Epoch 6/10\n",
            "189/189 [==============================] - 2s 10ms/step - loss: 0.4540 - categorical_accuracy: 0.6534 - val_loss: 0.3515 - val_categorical_accuracy: 0.8298 - lr: 9.5099e-04\n",
            "Epoch 7/10\n",
            "189/189 [==============================] - 2s 9ms/step - loss: 0.4605 - categorical_accuracy: 0.6402 - val_loss: 0.3383 - val_categorical_accuracy: 0.8298 - lr: 9.4148e-04\n",
            "Epoch 8/10\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.4438 - categorical_accuracy: 0.6429 - val_loss: 0.3261 - val_categorical_accuracy: 0.8298 - lr: 9.3207e-04\n",
            "Epoch 9/10\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.4306 - categorical_accuracy: 0.6746 - val_loss: 0.3139 - val_categorical_accuracy: 0.8298 - lr: 9.2274e-04\n",
            "Epoch 10/10\n",
            "189/189 [==============================] - 1s 7ms/step - loss: 0.4234 - categorical_accuracy: 0.6746 - val_loss: 0.3024 - val_categorical_accuracy: 0.8298 - lr: 9.1352e-04\n"
          ]
        }
      ],
      "source": [
        "# Configure the model training process and conduct training process\n",
        "hparams = gesture_recognizer.HParams(export_dir=\"exported_model\")\n",
        "options = gesture_recognizer.GestureRecognizerOptions(hparams=hparams)\n",
        "model = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    options=options\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfMz1gKC-Fr9",
        "outputId": "41ce66d8-a7cf-4440-8ec1-03281fa79c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 1s 3ms/step - loss: 0.2135 - categorical_accuracy: 0.8125\n",
            "Test loss:0.21347595751285553, Test accuracy:0.8125\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the process\n",
        "loss, acc = model.evaluate(test_data, batch_size=1)\n",
        "print(f\"Test loss:{loss}, Test accuracy:{acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGBhycT2-Vqo",
        "outputId": "27750e04-d4a5-41b7-bd9e-888f1631f591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tflite to /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Downloading https://storage.googleapis.com/mediapipe-assets/canned_gesture_classifier.tflite to /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n",
            "best_model_weights.data-00000-of-00001\tcheckpoint    gesture_recognizer.task  metadata.json\n",
            "best_model_weights.index\t\tepoch_models  logs\n"
          ]
        }
      ],
      "source": [
        "# export the model\n",
        "model.export_model()\n",
        "!ls exported_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OLOTb-UmBClx",
        "outputId": "a586cfaa-ff6a-4f50-e79a-5e2465780bd3"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d9612cd9-2bd5-495d-8f98-266c2d3b2cf3\", \"gesture_recognizer.task\", 8460859)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# download the model for project to use.\n",
        "files.download('exported_model/gesture_recognizer.task')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
